A busca por alto desempenho em aplicações de propósito geral e científicas, tem-se voltado para a exploração do processamento paralelo fornecido por placas gráficas (GPU), que integradas com o processamento já fornecido pelo host (CPU) potencializado com a multiplicidade de núcleos. As GPUs funcionam como dispositivos de aceleração, possibilitando que o código a ser executado possa ser dividido entre CPU-GPU. Para fins de aceleração de execução, porções menores do código, sejam elas sequenciais ou levemente paralelas podem ser escalonadas para a CPU, com aplicação de modelos de programação como o OpenMP \cite{Openmp:site} \cite{Chapman:2007} e o código fortemente baseado em paralelismo de dados e \textit{loops} que dominam o tempo de execução de uma aplicação, para a uma GPU. Essa execução intercalada deve considerar o equilíbrio entre CPU-GPU para que seja interessante sua utilização, pois depende do nível de processamento exigido, da carga da tarefa a ser executada, do custo de envio e do tempo para a cópia de dados entre as memórias principal e do dispositivo, se o tempo gasto para execução na GPU somado ao tempo de transferência (envio de entradas e recuperação dos resultados) for maior que o tempo de execução na CPU, certamente o processo de aceleração não será vantajoso.

Os desenvolvedores para GPU enfrentam as mesmas dificuldades encontradas em outros modelos de programação paralela. No geral, o \textit{hardware} disponível nem sempre fornece uma API de programação simples, amigável, o que exige do desenvolvedor o aprendizado de uma nova linguagem, de um novo paradigma de desenvolvimento. No caso GPU, a principal dificuldade está no fato do que é disponibilizado ao programador é o paralelismo explícito, isto é, toda a estrutura, o arranjo das \textit{threads} em blocos, e estes por sua vez em grids fica sob a responsabilidade do desenvolvedor.

A busca por ferramentas que facilitem o desevolvimento de aplicações paralelas, diminuindo a complexidade envolvida na programação, tem ganho grande importância. Projetos tem movido esforços para prover mecanismos que facilitem o desenvolvimento dessas aplicações, os resultados alcançados tem sido satisfatórios, porém estão longe do ideal que seria a paralelização automática, sem a necessidade de alterações no código original.

O que nota-se é a transferência da complexidade de um cenário para outro, as técnicas existentes utilizam-se de notações no código, são inseridas diretivas para que as ferramentas propostas gerem o código alvo para essas plataformas. Exigindo ainda do usuário a descrição, especificação explícita de como a ferramenta deve paralelizar o código. São abordagens que transformam o código original em código paralelo sem antes otimizá-lo para as características do dispositivo alvo que servirá de acelerador.

Nossa proposta é o estudo técnicas de compilação e otimização de código, principalmente para \textit{loops} que dominam o tempo de execução, para que possamos aplicar essas técnicas no código original antes do processo de paralelização para o dispositivo alvo, com a criação de \textit{kernels} a serem lançados no dispositivo. Essas técnicas se tornam padrões para modificações no código, que sendo aplicadas antes do processo de paralelização podem melhorar o tempo de execução do código original. Após a melhoria do código original, então o processo de transformação para a versão paralela dirigida ao dispositivo acelerador.

Alguns trabalhos tem se dedicado à exploração desse assunto no intuito de transpor essa dificuldade com a utilização de ferramentas que a partir de um código original, anotado ou não, possa gerar código a ser compilado para \texttt{GPU}. Isso facilita o papel do desenvolvedor, pois antes teria de desenvolver uma solução específica para cada problema, e com o apoio dessas ferramentas podem abstrair soluções. O objetivo de anotar o código, é fornecer sugestões ao compilador ou tradutor para que o processo de otimização de regiões consideradas paralelizáveis possa ser dirigido, fornecendo informações adicionais à ferramenta.
