#include <stdio.h>

// includes CUDA
#include <cuda_runtime.h>

#include <helper_cuda.h>
#include <helper_functions.h> // helper utility functions

// Variables
float* h_A;
float* h_B;
float* h_C;
float* d_A;
float* d_B;
float* d_C;
bool noprompt = false;

// Functions
void CleanupResources(void);
void RandomInit(float*, int);
void ParseArguments(int, char**);

////////////////////////////////////////////////////////////////////////////////
// These are CUDA Helper functions

// This will output the proper CUDA error strings in the event that a CUDA host call returns an error
#define checkCudaErrors(err)  __checkCudaErrors (err, __FILE__, __LINE__)

inline void __checkCudaErrors(cudaError err, const char *file, const int line )
{
    if(cudaSuccess != err)
    {
        fprintf(stderr, "%s(%i) : CUDA Runtime API error %d: %s.\n",file, line, (int)err, cudaGetErrorString( err ) );
        exit(-1);        
    }
}

// This will output the proper error string when calling cudaGetLastError
#define getLastCudaError(msg)      __getLastCudaError (msg, __FILE__, __LINE__)

inline void __getLastCudaError(const char *errorMessage, const char *file, const int line )
{
    cudaError_t err = cudaGetLastError();
    if (cudaSuccess != err)
    {
        fprintf(stderr, "%s(%i) : getLastCudaError() CUDA error : %s : (%d) %s.\n",
        file, line, errorMessage, (int)err, cudaGetErrorString( err ) );
        exit(-1);
    }
}

// end of CUDA Helper Functions


// Device code
__global__ void VecAdd(const float* A, const float* B, float* C, int N)
{
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i < N)
        C[i] = A[i] + B[i];
}

// Code generated by p4a.
__device__ void p4a_kernel_main_1(int i, float *a, float *b, float *c, int n)
{
   if (i<=n-1)
   c[i] = a[i]+b[i];
}

__global__ void p4a_wrapper_main_1(int i, float *a, float *b, float *c, int n)
{
   i = (blockIdx.x*blockDim.x + threadIdx.x);
   p4a_kernel_main_1(i, a, b, c, n);
}
// End Code generated by p4a.


// Host code
int main(int argc, char** argv)
{
    shrQAStart(argc, argv);

    printf("Vector Addition\n");
    int N = 50000;
    size_t size = N * sizeof(float);
    ParseArguments(argc, argv);

    // Allocate input vectors h_A and h_B in host memory
    h_A = (float*)malloc(size);
    if (h_A == 0) CleanupResources();
    h_B = (float*)malloc(size);
    if (h_B == 0) CleanupResources();
    h_C = (float*)malloc(size);
    if (h_C == 0) CleanupResources();
    
    // Initialize input vectors
    RandomInit(h_A, N);
    RandomInit(h_B, N);

    // Allocate vectors in device memory
    checkCudaErrors( cudaMalloc((void**)&d_A, size) );
    checkCudaErrors( cudaMalloc((void**)&d_B, size) );
    checkCudaErrors( cudaMalloc((void**)&d_C, size) );

    // Copy vectors from host memory to device memory
    checkCudaErrors( cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice) );
    checkCudaErrors( cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice) );

    // Invoke kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    int i = 0;

    // create cuda event handles
    cudaEvent_t start, stop;
    checkCudaErrors( cudaEventCreate(&start) );
    checkCudaErrors( cudaEventCreate(&stop) );

    StopWatchInterface *timerKernel1 = NULL;
    sdkCreateTimer(&timerKernel1);
    sdkResetTimer(&timerKernel1);

    // checkCudaErrors( cudaDeviceSynchronize() );
    float gpu_time = 0.0f;

    sdkStartTimer(&timerKernel1);
    cudaEventRecord(start, 0);
    // Kernel launch.
    p4a_wrapper_main_1<<<blocksPerGrid, threadsPerBlock>>>(i, d_A, d_B, d_C, N);
    cudaEventRecord(stop, 0);
    sdkStopTimer(&timerKernel1);

    checkCudaErrors( cudaEventElapsedTime(&gpu_time, start, stop) );

    // print the cpu and gpu times
    printf("time spent executing by the GPU: %.2f\n", gpu_time);
    printf("time spent by CPU in CUDA calls: %.2f\n", sdkGetTimerValue(&timerKernel1) );
    
    StopWatchInterface *timerKernel2 = NULL;
    sdkCreateTimer(&timerKernel2);
    sdkResetTimer(&timerKernel2);

    // checkCudaErrors( cudaDeviceSynchronize() );
    float gpu_time2 = 0.0f;

    sdkStartTimer(&timerKernel2);
    cudaEventRecord(start, 0);
    // Kernel launch.
    VecAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);
    cudaEventRecord(stop, 0);
    sdkStopTimer(&timerKernel2);

    checkCudaErrors( cudaEventElapsedTime(&gpu_time2, start, stop) );

    // print the cpu and gpu times
    printf("time spent executing by the GPU: %.2f\n", gpu_time2);
    printf("time spent by CPU in CUDA calls: %.2f\n", sdkGetTimerValue(&timerKernel2) );

    cudaThreadSynchronize();

    getLastCudaError("kernel launch failure");
#ifdef _DEBUG
    checkCudaErrors( cudaDeviceSynchronize() );
#endif

    // Copy result from device memory to host memory
    // h_C contains the result in host memory
    checkCudaErrors( cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost) );
    // Verify Result.
    int j;    
    // for (j = 0; j < N; ++j) {
    //    printf("(%f - %f) ", h_A[j] + h_B[j], h_C[j]);
    // }

    for (j = 0; j < N; ++j) {
        float sum = h_A[j] + h_B[j];
        if (fabs(h_C[j] - sum) > 1e-5)
            break;
    }

    CleanupResources();
    shrQAFinishExit(argc, (const char **)argv, (j==N) ? QA_PASSED : QA_FAILED);
}

void CleanupResources(void)
{
    // Free device memory
    if (d_A)
        cudaFree(d_A);
    if (d_B)
        cudaFree(d_B);
    if (d_C)
        cudaFree(d_C);

    // Free host memory
    if (h_A)
        free(h_A);
    if (h_B)
        free(h_B);
    if (h_C)
        free(h_C);
        
    cudaDeviceReset();
}

// Allocates an array with random float entries.
void RandomInit(float* data, int n)
{
    for (int i = 0; i < n; ++i)
        data[i] = rand() / (float)RAND_MAX;
}

// Parse program arguments
void ParseArguments(int argc, char** argv)
{
    for (int i = 0; i < argc; ++i) {
        if (strcmp(argv[i], "--noprompt") == 0 ||
            strcmp(argv[i], "-noprompt") == 0) 
        {
            noprompt = true;
            break;
        }
    }
}
